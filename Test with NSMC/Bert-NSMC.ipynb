{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 8000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/ratings_train.txt', sep='\\t')\n",
    "test_df = pd.read_csv('./data/ratings_test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "train_df = train_df.sample(frac=0.8, random_state=999)\n",
    "test_df = test_df.sample(frac=0.8, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119996"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 이 영화(제작과정포함)를 접한 후 결론 → 샤론스톤은 쓰레기다. [SEP]\n",
      "['[CLS]', '이', '영화', '(', '제작', '##과', '##정', '##포', '##함', ')', '를', '접', '##한', '후', '결', '##론', '→', '샤', '##론', '##스', '##톤', '##은', '쓰', '##레', '##기', '##다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "pad_sequences = tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9638,  42428,    113, 104865,  11882,  16605,  55530,\n",
       "        48533,    114,   9233,   9669,  11102,  10003,   8881,  42769,\n",
       "         1791,   9421,  42769,  12605, 119358,  10892,   9511,  56645,\n",
       "        12310,  11903,    119,    102,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=2018, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류를 위한 BERT 모델 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 1\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "y_true = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정확도 계산 함수\n",
    "# def flat_accuracy(preds, labels):\n",
    "#     global y_pred\n",
    "#     global y_true\n",
    "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#     labels_flat = labels.flatten()\n",
    "#     y_pred += pred_flat\n",
    "#     y_true += labels_flat\n",
    "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids , m , la =  next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 500/3375 [02:12<12:41,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   500  of  3,375.    Elapsed: 0:02:12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1000/3375 [04:24<10:28,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,000  of  3,375.    Elapsed: 0:04:25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1500/3375 [06:37<08:16,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,500  of  3,375.    Elapsed: 0:06:37.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2000/3375 [08:49<06:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,000  of  3,375.    Elapsed: 0:08:49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2500/3375 [11:01<03:50,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,500  of  3,375.    Elapsed: 0:11:01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 3000/3375 [13:13<01:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,000  of  3,375.    Elapsed: 0:13:13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [14:51<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:14:52\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y_pred' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a24296d45738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# 출력 로짓과 라벨을 비교하여 정확도 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtmp_eval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0meval_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_eval_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mnb_eval_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-8c9c08e523a3>\u001b[0m in \u001b[0;36mflat_accuracy\u001b[0;34m(preds, labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred_flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels_flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_flat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels_flat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'y_pred' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask,labels=b_labels)\n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:30\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for batch in validation_dataloader:\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat =  label_ids.flatten()\n",
    "    y_pred = np.concatenate((y_pred,pred_flat),axis=None)\n",
    "    y_true = np.concatenate((y_true,labels_flat),axis=None)\n",
    "    tmp_eval_accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Pos', 'Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pos       0.86      0.84      0.85      5961\n",
      "         Neg       0.85      0.87      0.86      6039\n",
      "\n",
      "    accuracy                           0.86     12000\n",
      "   macro avg       0.86      0.86      0.86     12000\n",
      "weighted avg       0.86      0.86      0.86     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2946a14e0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
